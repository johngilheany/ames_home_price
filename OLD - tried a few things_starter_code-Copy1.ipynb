{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5bcd448-53b9-4a30-9c02-235c72f5f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected variables + LR Model with OHE only\n",
    "# Score: 31k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8596c9-c719-4df2-b2c5-7ea7964eda59",
   "metadata": {},
   "source": [
    "# 1. EDA and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c416cec-4e4b-44cf-a15e-e12b7949e8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6646ac16-fce1-48bc-865f-5ab95732749e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "housing = pd.read_csv('datasets/train.csv')\n",
    "housing_test = pd.read_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f5847-ceb4-4a53-86ce-b63ca73caeda",
   "metadata": {},
   "source": [
    "### Read through data dictionary, decide on which variables to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39ccf0b-f7f2-40b3-ac3b-fedcfe2389ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove spaces in col names b/c data dictionary col names do not include spaces\n",
    "housing.columns = [n.replace(\" \", \"\") for n in housing.columns]\n",
    "\n",
    "# Save var names in txt file\n",
    "# Create function to get variable names into list from txt file\n",
    "# https://stackoverflow.com/questions/23372086/how-would-i-read-only-the-first-word-of-each-line-of-a-text-file\n",
    "def get_var_name(txt_file):\n",
    "    vars = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            vars.append(line.split(None, 1)[0][:-1])\n",
    "    return vars\n",
    "\n",
    "init_vars = get_var_name('datasets/initial_vars.txt')\n",
    "housing_init = housing[init_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ac944b-f4ea-432c-a8de-2ebe21fcc0b3",
   "metadata": {},
   "source": [
    "### Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489a1100-682f-483f-88ac-82bb2ab474a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA values. \n",
    "# housing_init.isna().mean()\n",
    "# Replace NAs with 0. They are not missing values, but 0 (i.e. basement bathroom is 0 not NA if there is no basement)\n",
    "# https://www.geeksforgeeks.org/replace-nan-values-with-zeros-in-pandas-dataframe/\n",
    "housing_init = housing_init.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f377e9-c81f-43d8-b639-ecc92ae8dba1",
   "metadata": {},
   "source": [
    "### Variable Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaef67e-fcfe-4b0f-bef0-9386a337dada",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Add 'age' of home to be time since build or latest remodel. Assume data is from 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c267f586-4858-46c3-a477-f5065a56dd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate age as 2011 - year of latest remodel or build\n",
    "# housing_init['YearRemod/Add'].groupby(housing_init['YearRemod/Add']).count()\n",
    "housing_init['Age'] = 2011 - housing_init['YearRemod/Add']\n",
    "housing_init.drop(columns =['YearRemod/Add'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f38339f-5e55-4ffd-93d2-ddf13b1c1dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2051.000000\n",
       "mean       26.809849\n",
       "std        21.036250\n",
       "min         1.000000\n",
       "25%         7.000000\n",
       "50%        18.000000\n",
       "75%        46.500000\n",
       "max        61.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ages range from 1-61 years, which makes sense \n",
    "housing_init['Age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271d44f-8aac-4f40-ae61-8e4eea4ca805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Add 'TotalBaths' as new variable, adding up basement full bathrooms, basement half bathrooms, full bathrooms above grade, and half bathrooms above grade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8413d8e2-ea25-40e6-9e23-a6f023a2318c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new column in dataset for total number of bathrooms\n",
    "housing_init['TotalBaths'] = housing_init['BsmtFullBath'] + 0.5*housing_init['BsmtHalfBath'] + housing_init['FullBath'] + 0.5*housing_init['HalfBath']\n",
    "housing_init['TotalBaths'].describe()\n",
    "housing_init.drop(columns =['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'], inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eba827-39dd-4f82-8443-3407cac4aa05",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Add 'OutdoorSF' as outdoor square feet, which represents the sum of wood deck, open porch, enclosed porch, 3 screen porch and screen porch square feet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d5bd1b-876c-4538-ae70-566fd72857d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new column for outdoor square footage\n",
    "housing_init['OutdoorSF'] = housing_init['WoodDeckSF'] + housing_init['OpenPorchSF'] + housing_init['EnclosedPorch'] + housing_init['3SsnPorch'] + housing_init['ScreenPorch'] \n",
    "housing_init['OutdoorSF'].describe()\n",
    "housing_init.drop(columns =['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'], inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651d816-56c5-4d4d-bfe5-762f7a59f4b2",
   "metadata": {},
   "source": [
    "#### Convert month sold into calendar year quarter (Q1 for Jan-Mar, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a131a47e-192b-46fb-9bd7-2d43cd7bb9e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quarter\n",
       "Q1    351\n",
       "Q2    817\n",
       "Q3    579\n",
       "Q4    304\n",
       "Name: Quarter, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.nar.realtor/blogs/economists-outlook/seasonality-in-the-housing-market\n",
    "housing_init['MoSold'].describe()\n",
    "\n",
    "# Cast quarter to new column from month \n",
    "housing_init['Quarter'] = np.nan\n",
    "q = []\n",
    "for month in housing_init['MoSold']:\n",
    "    if month < 4:\n",
    "        q.append('Q1')\n",
    "    elif month < 7:\n",
    "        q.append('Q2')\n",
    "    elif month < 10:\n",
    "        q.append('Q3')\n",
    "    else:\n",
    "        q.append('Q4')\n",
    "housing_init['Quarter'] = q\n",
    "\n",
    "housing_init.drop(columns =['MoSold'], inplace=True)\n",
    "housing_init['Quarter'].groupby(housing_init['Quarter']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be416fef-2a0f-483b-9b71-b84e75fb0cc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Convert year to binary variable 'GFC', before and after 2008 (Great Financial Crisis) which negatively impacted real estate prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0bdbbf8-e1e8-4158-a4a6-36b6f99939e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GFC\n",
       "0     234\n",
       "1    1817\n",
       "Name: GFC, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_init['SalePrice'].groupby(housing_init['YrSold']).mean()\n",
    "\n",
    "# Cast yr sold as before/after GFC\n",
    "housing_init['GFC'] = np.nan\n",
    "year = []\n",
    "for yr in housing_init['YrSold']:\n",
    "    if yr > 2009:\n",
    "        year.append('0')\n",
    "    else:\n",
    "        year.append('1')\n",
    "housing_init['GFC'] = year\n",
    "\n",
    "housing_init.drop(columns =['YrSold'], inplace=True)\n",
    "housing_init['GFC'].groupby(housing_init['GFC']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfd9aa-4170-4df2-970a-6039402a2ea8",
   "metadata": {},
   "source": [
    "### Variable Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1be9a8f8-2ff8-42c4-a0c8-39c026c9f083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# housing_init.info()\n",
    "# Break out dummy vars. Convert variables to categorical (do this after TTS) \n",
    "housing_init_dummy = housing_init.drop(columns = ['TotalBsmtSF', 'GrLivArea', 'MiscVal', 'PoolArea', 'SalePrice', 'Age', 'OutdoorSF', 'TotRmsAbvGrd', 'GarageCars', 'Fireplaces', 'TotalBaths'])\n",
    "# Break out numeric variables. Ensure in right variable type (float/int)\n",
    "housing_init_num = housing_init[['TotalBsmtSF', 'GrLivArea', 'MiscVal', 'PoolArea', 'Age', 'OutdoorSF', 'TotRmsAbvGrd', 'GarageCars', 'Fireplaces', 'TotalBaths']]\n",
    "# housing_init_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c38c8e7c-168a-4d8e-a3ea-edd8d4fb9e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create combined new data set for X variables\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "housing_xvars = pd.concat([housing_init_dummy, housing_init_num], axis=1)\n",
    "# housing_xvars.head()\n",
    "# housing_xvars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651247d-2d73-4122-8cf0-edc2c2269dc8",
   "metadata": {},
   "source": [
    "# Preproccesing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd917fe-6ead-4ff7-9751-0aadb60c6317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1538, 20) (1538,)\n",
      "(513, 20) (513,)\n"
     ]
    }
   ],
   "source": [
    "# Define X and y variables\n",
    "X = housing_xvars\n",
    "y = housing_init['SalePrice']\n",
    "\n",
    "# TTS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 95)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a1b8dda-17d8-4983-9cd5-e5a03fa1266a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13478\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\13478\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m X_test_oh \u001b[38;5;241m=\u001b[39m oh\u001b[38;5;241m.\u001b[39mfit_transform(X_test)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# X_oh = oh.fit_transform(X)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_oh \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(X_test_oh, columns \u001b[38;5;241m=\u001b[39m oh\u001b[38;5;241m.\u001b[39mget_feature_names_out()), X_train_oh], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# housing_init_dummy_oh = oh.fit_transform(housing_init_dummy)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# housing_xvars_oh = pd.concat([pd.DataFrame(housing_init_dummy_oh, columns = oh.get_feature_names_out()), housing_init_num], axis=1)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m X_oh\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:458\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    454\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    455\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         )\n\u001b[1;32m--> 458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    460\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# get the sample\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;66;03m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# Convert variables to categorical with OHE\n",
    "oh = OneHotEncoder(sparse = False, drop = 'first')\n",
    "X_train_oh = oh.fit_transform(X_train)\n",
    "X_test_oh = oh.fit_transform(X_test)\n",
    "# X_oh = oh.fit_transform(X)\n",
    "X_oh = pd.concat([pd.DataFrame(X_test_oh, columns = oh.get_feature_names_out()), X_train_oh], axis=1)\n",
    "# housing_init_dummy_oh = oh.fit_transform(housing_init_dummy)\n",
    "# housing_xvars_oh = pd.concat([pd.DataFrame(housing_init_dummy_oh, columns = oh.get_feature_names_out()), housing_init_num], axis=1)\n",
    "X_oh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c37aa-83a4-43bb-b719-a302d6e62790",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90ff7925-15d7-4181-9f61-a8af9fd4d4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999700300845832\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1184 features, but LinearRegression is expecting 2272 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(X_train_oh, y_train)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(lr\u001b[38;5;241m.\u001b[39mscore(X_train_oh, y_train))\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(lr\u001b[38;5;241m.\u001b[39mscore(X_test_oh, y_test))\n\u001b[0;32m      5\u001b[0m preds \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_oh)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:759\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \n\u001b[0;32m    719\u001b[0m \u001b[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m--> 759\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_function(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    367\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1184 features, but LinearRegression is expecting 2272 features as input."
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_oh, y_train)\n",
    "print(lr.score(X_train_oh, y_train))\n",
    "print(lr.score(X_test_oh, y_test))\n",
    "preds = lr.predict(X_oh)\n",
    "# preds.shape\n",
    "# 0.8873364495160501\n",
    "# 0.877606905706273"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f71da2-7854-4a66-bfe0-450560e6c3bf",
   "metadata": {},
   "source": [
    "### Convert test data in same way as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a71c53-586b-4a68-9975-aaf64af42b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_test0 = pd.read_csv('datasets/test-Copy1.csv')\n",
    "housing_test0.columns = [n.replace(\" \", \"\") for n in housing_test0.columns]\n",
    "\n",
    "init_vars1 = get_var_name('datasets/initial_vars-Copy1.txt')\n",
    "housing_test1 = housing_test0[init_vars1]\n",
    "\n",
    "housing_test1 = housing_test1.fillna(0)\n",
    "\n",
    "housing_test1['Age'] = 2011 - housing_test1['YearRemod/Add']\n",
    "housing_test1.drop(columns =['YearRemod/Add'], inplace= True)\n",
    "\n",
    "housing_test1['TotalBaths'] = housing_test1['BsmtFullBath'] + 0.5*housing_test1['BsmtHalfBath'] + housing_test1['FullBath'] + 0.5*housing_test1['HalfBath']\n",
    "housing_test1.drop(columns =['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'], inplace= True)\n",
    "\n",
    "housing_test1['OutdoorSF'] = housing_test1['WoodDeckSF'] + housing_test1['OpenPorchSF'] + housing_test1['EnclosedPorch'] + housing_test1['3SsnPorch'] + housing_test1['ScreenPorch'] \n",
    "housing_test1.drop(columns =['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'], inplace= True)\n",
    "\n",
    "housing_test1['Quarter'] = np.nan\n",
    "q = []\n",
    "for month in housing_test1['MoSold']:\n",
    "    if month < 4:\n",
    "        q.append('Q1')\n",
    "    elif month < 7:\n",
    "        q.append('Q2')\n",
    "    elif month < 10:\n",
    "        q.append('Q3')\n",
    "    else:\n",
    "        q.append('Q4')\n",
    "housing_test1['Quarter'] = q\n",
    "housing_test1.drop(columns =['MoSold'], inplace=True)\n",
    "\n",
    "housing_test1['GFC'] = np.nan\n",
    "year = []\n",
    "for yr in housing_test1['YrSold']:\n",
    "    if yr > 2009:\n",
    "        year.append('0')\n",
    "    else:\n",
    "        year.append('1')\n",
    "housing_test1['GFC'] = year\n",
    "housing_test1.drop(columns =['YrSold'], inplace=True)\n",
    "\n",
    "housing_test1_dummy = housing_test1.drop(columns = ['TotalBsmtSF', 'GrLivArea', 'MiscVal', 'PoolArea', 'Age', 'OutdoorSF', 'TotRmsAbvGrd', 'GarageCars', 'Fireplaces', 'TotalBaths'])\n",
    "housing_test1_num = housing_test1[['TotalBsmtSF', 'GrLivArea', 'MiscVal', 'PoolArea', 'Age', 'OutdoorSF', 'TotRmsAbvGrd', 'GarageCars', 'Fireplaces', 'TotalBaths']]\n",
    "oh = OneHotEncoder(sparse = False, drop = 'first')\n",
    "housing_test1_dummy_oh = oh.fit_transform(housing_test1_dummy)\n",
    "housing_xvars_test1_oh = pd.concat([pd.DataFrame(housing_test1_dummy_oh, columns = oh.get_feature_names_out()), housing_test1_num], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dac1d7-9b08-4340-8933-d4b1d442fe15",
   "metadata": {},
   "source": [
    "### Run model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf798b7-9667-496e-92a2-3281d8d95418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Need same columns present in test data and train data. \n",
    "# Identify missing columns bw test and training data then add as 0s where appropriate\n",
    "# housing_xvars_test1_oh\n",
    "miss_cols = housing_xvars_oh.columns.difference(housing_xvars_test1_oh.columns)\n",
    "\n",
    "# Add missing columns to test data, fill with 0s\n",
    "housing_xvars_test1_oh[miss_cols] = 0\n",
    "# housing_xvars_oh.columns\n",
    "\n",
    "# Sort columns in test data so in same order as training data\n",
    "# housing_xvars_test1_oh_sorted = pd.DataFrame(housing_xvars_test1_oh, columns = housing_xvars_oh.columns)\n",
    "housing_xvars_test1_oh = housing_xvars_test1_oh[housing_xvars_oh.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcfe2b-6ff5-4eb4-a60d-4609563e00a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_xvars_test1_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce66c5-c384-46ac-b26b-e16ceba9f65e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get predictions on test data \n",
    "test_preds = lr.predict(housing_xvars_test1_oh)\n",
    "\n",
    "# Fit test data with model\n",
    "housing_test0['SalePrice'] = test_preds\n",
    "# housing_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40050488-944e-47a8-b77d-a104331f53d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save excel for submission\n",
    "submission4 = housing_test0[['Id', 'SalePrice']]\n",
    "submission4.set_index('Id', inplace = True)\n",
    "submission4.to_csv('submission4.csv')\n",
    "# submission4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
